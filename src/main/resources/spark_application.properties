# HDFS
hdfs.application.dir.path = /user/osboxes/applications/spark_sql_pipeline
hdfs.application.pipeline.dir.path = ${hdfs.application.dir.path}/json
hdfs.application.csv.dir.path = ${hdfs.application.dir.path}/csv
hdfs.pipeline.initialLoad.file.path = ${hdfs.application.pipeline.dir.path}/initial_load.json
hdfs.pipeline.initialLoad.csv.path = ${hdfs.application.csv.dir.path}/pipeline_info.csv

# Hive
hive.db.pipelineRunner.name = pipeline_runner
hive.table.pipelineInfo.name = pipeline_info
hive.table.pipelineLog.name = pipeline_log

# Spark
spark.saveMode.overwrite = overwrite

# Yarn
yarn.application.history.ui.url = http://quickstart-bigdata:8088/cluster/app